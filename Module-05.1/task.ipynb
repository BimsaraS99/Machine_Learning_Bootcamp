{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156812b7",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "088282a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357221c",
   "metadata": {},
   "source": [
    "## Define Image and Dataset Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bead21df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"train-set\"        # Folder where images are stored\n",
    "image_size = 100              # Image height and width\n",
    "num_images_per_class = 100    # Optional: number of images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "266d479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store features and labels\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee172e00",
   "metadata": {},
   "source": [
    "## Load Images from Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå This block loads images from folders: 'class_0' and 'class_1'\n",
    "# It reads each image, converts it to grayscale, resizes to 100x100 pixels,\n",
    "# and stores the image data and its label.\n",
    "\n",
    "# We loop through the two classes: 0 and 1\n",
    "for label in [0, 1]:\n",
    "    \n",
    "    # Get the folder name for the class, like: 'dataset/class_0' or 'dataset/class_1'\n",
    "    folder_path = os.path.join(output_dir, f\"{label}\")\n",
    "    \n",
    "    # Go through each file in the folder\n",
    "    --------------------code------------------------\n",
    "        \n",
    "        # Only process files that are PNG images\n",
    "        --------------------code------------------------\n",
    "            \n",
    "            # Create the full path to the image file\n",
    "            --------------------code------------------------\n",
    "            \n",
    "            # üñºÔ∏è Open the image using PIL and convert it to grayscale (L = luminance)\n",
    "            --------------------code------------------------\n",
    "            \n",
    "            # üìè Resize the image to 100x100 pixels (in case it's not already)\n",
    "            --------------------code------------------------\n",
    "            \n",
    "            # üßÆ Convert the image into a 2D NumPy array and store it\n",
    "            # We'll flatten it later in another step\n",
    "            --------------------code------------------------\n",
    "            --------------------code------------------------\n",
    "            \n",
    "            # üè∑Ô∏è Add the label (0 or 1) corresponding to the class folder\n",
    "            y.append(label)\n",
    "\n",
    "# ‚úÖ Now 'X' contains the image data, and 'y' contains the labels!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5b9b4",
   "metadata": {},
   "source": [
    "## Flatten Images into Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebd7e2",
   "metadata": {},
   "source": [
    "Explain why images need to be flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd1c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (200, 10000)\n",
      "y shape: (200,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "211d5d1b",
   "metadata": {},
   "source": [
    "## Split Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 160\n",
      "Testing samples: 40\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "748fb071",
   "metadata": {},
   "source": [
    "## Train the SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a667e55e",
   "metadata": {},
   "source": [
    "Explain how the SVM algorithm works and help me understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc628377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model training complete.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c93d7f8",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7534e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Evaluation complete.\n",
      "Accuracy: 0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93        21\n",
      "           1       0.94      0.89      0.92        19\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.92      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff4b326a",
   "metadata": {},
   "source": [
    "## Predict on given images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "181a571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Circle\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def predict_image(image_path):\n",
    "    # Open and preprocess the image\n",
    "    image = Image.open(image_path).convert('L').resize((image_size, image_size))\n",
    "    image_array = np.array(image)\n",
    "    \n",
    "    # Show the image\n",
    "    plt.imshow(image_array, cmap='gray')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Flatten and reshape for prediction\n",
    "    image_flat = image_array.flatten().reshape(1, -1)\n",
    "    \n",
    "    # Predict using the trained classifier\n",
    "    predicted_class = clf.predict(image_flat)[0]\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage:\n",
    "result = predict_image('test-set/1/img_5.png')\n",
    "res = [\"Squre\", \"Circle\"]\n",
    "print(f\"Predicted class: {res[result]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sliit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
